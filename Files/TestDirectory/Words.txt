Threads are the underlying tool for creating concurrency, so it has certain limitations. In particular: Although it is not difficult to pass data to a thread when it is started, it is difficult to get a "return value" from it when the thread joins. Often you have to create some shared fields (to get the "return value"). Also, catching and handling exceptions thrown by operations in the thread is cumbersome. After the thread is finished, it cannot be started again, instead it can only be joined (and block the current operating thread). These limitations affect the implementation of fine-grained concurrency. In other words, this approach makes it difficult to combine small concurrency into large concurrent operations (which is very important for asynchronous programming and will be covered in later chapters), and adds manual synchronization (such as using locks, signaling, etc.) ) dependencies, and can easily cause problems. Direct use of threads also has a performance impact, see Section 14.2.13 for details. And if you need to run a lot of concurrent I/O-intensive operations, thread-based approaches can consume hundreds of gigabytes of memory just in terms of the overhead of the threads themselves.